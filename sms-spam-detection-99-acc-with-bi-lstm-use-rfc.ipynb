{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div align=\"center\"><img src=\"https://www.icegif.com/wp-content/uploads/icegif-87.gif\" width=800/></div>","metadata":{}},{"cell_type":"markdown","source":"## What I want to do in this notebooküìô?\n##### spam detection, is a formal problem that all of us saw it in ML courses intros.\n\n##### the dataset we have contains thousands of text examples and labels(ham/spam), here goal is to create and train a model that has the best \n\n##### performance and can predict a text is spam or ham(not spam).\n\n##### in this notebook I want to solve this problem in four ways:\n#### `baseline_model` -> Random-Forest model to discover initial patterns(simple model)\n\n#### `model_1` -> Custom Text Vectorization, Embedding + Dense layers\n\n#### `model_2` -> Custom layers + Bidirectional-LSTM layers\n\n#### `model_3` -> USE embedding layer(transfer learning) + Sequential API","metadata":{}},{"cell_type":"code","source":"import numpy as np # numerical computing \nimport pandas as pd # data analysis, working with DataFrames\nimport matplotlib.pyplot as plt # visualizations\nimport seaborn as sns # visulizations ++\nimport tensorflow as tf # our main library, deep learning modellign\nfrom tensorflow import keras # keras library\nfrom tensorflow.keras import layers # for creating layers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-14T07:56:50.332768Z","iopub.execute_input":"2022-02-14T07:56:50.333098Z","iopub.status.idle":"2022-02-14T07:56:52.343813Z","shell.execute_reply.started":"2022-02-14T07:56:50.333047Z","shell.execute_reply":"2022-02-14T07:56:52.343033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\", encoding=\"latin-1\") # reading data","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:52.348704Z","iopub.execute_input":"2022-02-14T07:56:52.349153Z","iopub.status.idle":"2022-02-14T07:56:52.369697Z","shell.execute_reply.started":"2022-02-14T07:56:52.349117Z","shell.execute_reply":"2022-02-14T07:56:52.368959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Become One with the Data! üîç","metadata":{}},{"cell_type":"markdown","source":"<div align=\"center\"><img src=\"https://c.tenor.com/KGQ_42IC9vUAAAAC/spam-email.gif\" /></div>","metadata":{}},{"cell_type":"markdown","source":"<div align=\"center\"><img src=\"https://miro.medium.com/max/1400/0*ZzcKU607S3OWpn5I.jpg\" width=800/></div>","metadata":{}},{"cell_type":"markdown","source":"## Why actually an Spam SMS?\n>Scammers send fake text messages to trick you into giving them your personal information ‚Äì things like your password, account number, or Social Security number. If they get that information, they could gain access to your email, bank, or other accounts.\n\nhttps://www.consumer.ftc.gov/articles/how-recognize-and-report-spam-text-messages#:~:text=what%20to%20do.-,Spam%20Text%20Messages%20and%20Phishing,%2C%20bank%2C%20or%20other%20accounts.","metadata":{}},{"cell_type":"markdown","source":"# A defenition of spam detection:\n> This is called Spam Detection, and it is a binary classification problem. The reason to do this is simple: by detecting unsolicited and unwanted emails, we can prevent spam messages from creeping into the user's inbox, thereby improving user experience.\n\nhttps://towardsdatascience.com/spam-detection-in-emails-de0398ea3b48#:~:text=This%20is%20called%20Spam%20Detection,inbox%2C%20thereby%20improving%20user%20experience.","metadata":{}},{"cell_type":"markdown","source":"#### our dataset is SMS data not Email, but they are similar.","metadata":{}},{"cell_type":"code","source":"df.head() # an overview ","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:52.371471Z","iopub.execute_input":"2022-02-14T07:56:52.371679Z","iopub.status.idle":"2022-02-14T07:56:52.389113Z","shell.execute_reply.started":"2022-02-14T07:56:52.371654Z","shell.execute_reply":"2022-02-14T07:56:52.388448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### this dataset has three Unnamed columns that we don't need, so we just `drop` them\n#### also our label is in string form -> `spam` and `ham`, so we map them in numerical form","metadata":{}},{"cell_type":"code","source":"df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\ndf = df.rename(columns={'v1':'label', 'v2':'Text'})\ndf['label_in_num'] = df['label'].map({'ham':0,'spam':1})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:52.39164Z","iopub.execute_input":"2022-02-14T07:56:52.391902Z","iopub.status.idle":"2022-02-14T07:56:52.40626Z","shell.execute_reply.started":"2022-02-14T07:56:52.391868Z","shell.execute_reply":"2022-02-14T07:56:52.405414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### a bit Analysis!üìâ ","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=df['label']) # countplot for label","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:52.407785Z","iopub.execute_input":"2022-02-14T07:56:52.408077Z","iopub.status.idle":"2022-02-14T07:56:52.583849Z","shell.execute_reply.started":"2022-02-14T07:56:52.408028Z","shell.execute_reply":"2022-02-14T07:56:52.582978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:52.585353Z","iopub.execute_input":"2022-02-14T07:56:52.585592Z","iopub.status.idle":"2022-02-14T07:56:52.5953Z","shell.execute_reply.started":"2022-02-14T07:56:52.585558Z","shell.execute_reply":"2022-02-14T07:56:52.594508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Imbalanced case:\ndata points with ham label are 6.5 times more than points with spam labels,\n\nso this leads to a Imbalanced dataset.","metadata":{"execution":{"iopub.status.busy":"2022-02-11T09:42:11.631795Z","iopub.execute_input":"2022-02-11T09:42:11.632649Z","iopub.status.idle":"2022-02-11T09:42:11.640031Z","shell.execute_reply.started":"2022-02-11T09:42:11.632585Z","shell.execute_reply":"2022-02-11T09:42:11.639177Z"}}},{"cell_type":"code","source":"sns.countplot(x=[len(df.loc[i]['Text']) for i in range(len(df))])\nplt.xlabel('Text length')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:52.596876Z","iopub.execute_input":"2022-02-14T07:56:52.59734Z","iopub.status.idle":"2022-02-14T07:56:56.905063Z","shell.execute_reply.started":"2022-02-14T07:56:52.597305Z","shell.execute_reply":"2022-02-14T07:56:56.904387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We want these things:\n* number of words in the whole dataset\n* mean of word count in every row\n* total words in dataset","metadata":{}},{"cell_type":"code","source":"text_words_lengths = [len(df.loc[i]['Text'].split()) for i in range(0, len(df))]\ntotal_length = np.sum(text_words_lengths)\ntext_words_mean = int(np.mean(text_words_lengths))\nprint('we have ' + str(total_length) + ' words in our Dataframe')\nprint('the average word count in every scentence is ' + str(text_words_mean))\ntext_words_lengths[:5], total_length, text_words_mean","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:56.906393Z","iopub.execute_input":"2022-02-14T07:56:56.906811Z","iopub.status.idle":"2022-02-14T07:56:57.547333Z","shell.execute_reply.started":"2022-02-14T07:56:56.906771Z","shell.execute_reply":"2022-02-14T07:56:57.546527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test Split ‚úÇ, an Important Step! ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX, y = np.asanyarray(df['Text']), np.asanyarray(df['label_in_num'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\nlen(X_train), len(X_test), X_train[:2], y_train[:2]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:57.548852Z","iopub.execute_input":"2022-02-14T07:56:57.549404Z","iopub.status.idle":"2022-02-14T07:56:57.778774Z","shell.execute_reply.started":"2022-02-14T07:56:57.549357Z","shell.execute_reply":"2022-02-14T07:56:57.778075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model - Random Forest üå≤","metadata":{}},{"cell_type":"markdown","source":"<div align=\"center\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png\" /></div>","metadata":{}},{"cell_type":"markdown","source":"#### I chose Random Forest, because it can be a good model for start. we creat our baseline and then we try to beat it.\n##### `TFIDF` -> preprocessing the text data\n\n##### `Random-Forest` -> creating machine learning model","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\ntfidf_vec = TfidfVectorizer().fit(X_train)\nX_train_vec, X_test_vec = tfidf_vec.transform(X_train), tfidf_vec.transform(X_test)\nbaseline_model = RandomForestClassifier(n_estimators=250)\nbaseline_model.fit(X_train_vec, y_train)\n\nrandom_forest_accuracy = accuracy_score(y_test, baseline_model.predict(X_test_vec))\nprint(classification_report(y_test, baseline_model.predict(X_test_vec)))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:56:57.780099Z","iopub.execute_input":"2022-02-14T07:56:57.780508Z","iopub.status.idle":"2022-02-14T07:57:00.224483Z","shell.execute_reply.started":"2022-02-14T07:56:57.780471Z","shell.execute_reply":"2022-02-14T07:57:00.223714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusino matrix for baseline model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(baseline_model, X_test_vec, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:00.225829Z","iopub.execute_input":"2022-02-14T07:57:00.226255Z","iopub.status.idle":"2022-02-14T07:57:00.529645Z","shell.execute_reply.started":"2022-02-14T07:57:00.226217Z","shell.execute_reply":"2022-02-14T07:57:00.528956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Custom Text Vectorization and Embedding layers","metadata":{}},{"cell_type":"markdown","source":"### <div align=\"center\"><img src=\"https://www.pinecone.io/images/vector_embeddings.jpg\" width=1000/></div>","metadata":{}},{"cell_type":"markdown","source":"### Text Vectorization:\n>  Text Vectorization is the process of converting text into numerical representation. Here is some popular methods to accomplish text vectorization: Binary Term Frequency. Bag of Words (BoW) Term Frequency. (L1) Normalized Term Frequency. \n\nsource : [towards datascience](https://towardsdatascience.com/getting-started-with-text-vectorization-2f2efbec6685#:~:text=Text%20Vectorization%20is%20the%20process,(L1)%20Normalized%20Term%20Frequency)","metadata":{}},{"cell_type":"markdown","source":"### Word embedding:\n>  A word embedding is a learned representation for text where words that have the same meaning have a similar representation. ... Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network, and hence the technique is often lumped into the field of deep learning.\n\nsource : [machine learning mastery](https://machinelearningmastery.com/what-are-word-embeddings/#:~:text=A%20word%20embedding%20is%20a,meaning%20have%20a%20similar%20representation.&text=Each%20word%20is%20mapped%20to,the%20field%20of%20deep%20learning.)","metadata":{}},{"cell_type":"code","source":"MAXTOKENS = total_length\nOUTPUTLEN = text_words_mean\n\ntext_vec = layers.TextVectorization(\n    max_tokens=MAXTOKENS,\n    standardize='lower_and_strip_punctuation',\n    output_mode='int',\n    output_sequence_length=OUTPUTLEN\n)\n\ntext_vec.adapt(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:00.530889Z","iopub.execute_input":"2022-02-14T07:57:00.53265Z","iopub.status.idle":"2022-02-14T07:57:01.830064Z","shell.execute_reply.started":"2022-02-14T07:57:00.532606Z","shell.execute_reply":"2022-02-14T07:57:01.829246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_layer = layers.Embedding(\n    input_dim=MAXTOKENS,\n    output_dim=128,\n    embeddings_initializer='uniform',\n    input_length=OUTPUTLEN\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:01.833998Z","iopub.execute_input":"2022-02-14T07:57:01.834229Z","iopub.status.idle":"2022-02-14T07:57:01.840284Z","shell.execute_reply.started":"2022-02-14T07:57:01.834201Z","shell.execute_reply":"2022-02-14T07:57:01.839017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1 - Using our custom layers with 2 Dense layers","metadata":{}},{"cell_type":"code","source":"# Input layer\ninput_layer = layers.Input(shape=(1,), dtype=tf.string)\n# Text Vectorizatino layer\nvec_layer = text_vec(input_layer)\n# Embedding layer\nembedding_layer_model = embedding_layer(vec_layer)\n# Global Average Pooling layer\nx = layers.GlobalAveragePooling1D()(embedding_layer_model)\n# Flatten layer for Dense layers\nx = layers.Flatten()(x)\n# 32 units dense layer\nx = layers.Dense(32, activation='relu')(x)\n# output layer with sigmoid activation function\noutput_layer = layers.Dense(1, activation='sigmoid')(x)\n# final model\nmodel_1 = keras.Model(input_layer, output_layer)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:01.841553Z","iopub.execute_input":"2022-02-14T07:57:01.84253Z","iopub.status.idle":"2022-02-14T07:57:01.907004Z","shell.execute_reply.started":"2022-02-14T07:57:01.842493Z","shell.execute_reply":"2022-02-14T07:57:01.906219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile `model_1`","metadata":{}},{"cell_type":"code","source":"model_1.compile(optimizer=keras.optimizers.Adam(),\n               loss=keras.losses.BinaryCrossentropy(label_smoothing=0.5),\n               metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:01.908187Z","iopub.execute_input":"2022-02-14T07:57:01.90844Z","iopub.status.idle":"2022-02-14T07:57:01.923733Z","shell.execute_reply.started":"2022-02-14T07:57:01.908399Z","shell.execute_reply":"2022-02-14T07:57:01.923042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit the model","metadata":{}},{"cell_type":"code","source":"history_1 = model_1.fit(X_train,\n           y_train,\n           epochs=5,\n           validation_data=(X_test, y_test),\n           validation_steps=int(0.2 * len(X_test)))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:01.926401Z","iopub.execute_input":"2022-02-14T07:57:01.9266Z","iopub.status.idle":"2022-02-14T07:57:12.717708Z","shell.execute_reply.started":"2022-02-14T07:57:01.926576Z","shell.execute_reply":"2022-02-14T07:57:12.716926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history_1.history).plot()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:12.719557Z","iopub.execute_input":"2022-02-14T07:57:12.719925Z","iopub.status.idle":"2022-02-14T07:57:12.9567Z","shell.execute_reply.started":"2022-02-14T07:57:12.719879Z","shell.execute_reply":"2022-02-14T07:57:12.956011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# helper functions üõ† ","metadata":{}},{"cell_type":"markdown","source":"##### compile_model(), fit_model(), evaluate_model():\n##### I want to compile, fit and evaluate for a few models, so I just creat method to easily reuse the code over and over.","metadata":{}},{"cell_type":"code","source":"def compile_model(model):\n    '''\n    simply compile the model with adam optimzer\n    '''\n    model.compile(optimizer=keras.optimizers.Adam(),\n                 loss=keras.losses.BinaryCrossentropy(),\n                 metrics=['accuracy'])    \n\ndef fit_model(model, epochs, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n    '''\n    fit the model with given epochs, train and test data\n    '''\n    history = model.fit(X_train,\n              y_train,\n             epochs=epochs,\n             validation_data=(X_test, y_test),\n             validation_steps=int(0.2*len(X_test)))\n    return history\n ","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:12.958208Z","iopub.execute_input":"2022-02-14T07:57:12.958692Z","iopub.status.idle":"2022-02-14T07:57:12.965982Z","shell.execute_reply.started":"2022-02-14T07:57:12.958653Z","shell.execute_reply":"2022-02-14T07:57:12.965213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\ndef evaluate_model(model, X, y):\n    '''\n    evaluate the model and returns accuracy, precision, recall and f1-score \n    '''\n    y_preds = np.round(model.predict(X))\n    accuracy = accuracy_score(y, y_preds)\n    precision = precision_score(y, y_preds)\n    recall = recall_score(y, y_preds)\n    f1 = f1_score(y, y_preds)\n    \n    model_results_dict = {'accuracy':accuracy,\n                         'precision':precision,\n                         'recall':recall,\n                         'f1-score':f1}\n    \n    return model_results_dict","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:12.967115Z","iopub.execute_input":"2022-02-14T07:57:12.967406Z","iopub.status.idle":"2022-02-14T07:57:12.976454Z","shell.execute_reply.started":"2022-02-14T07:57:12.967359Z","shell.execute_reply":"2022-02-14T07:57:12.975646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2 - Bidirectional LSTM ","metadata":{}},{"cell_type":"markdown","source":"<img src=\"data:image/png;base64,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\" />","metadata":{}},{"cell_type":"markdown","source":"***A Bidirectional LSTM, or biLSTM, is a sequence processing model that consists of two LSTMs: one taking the input in a forward direction, and the other in a backwards direction. BiLSTMs effectively increase the amount of information available to the network, improving the context available to the algorithm (e.g. knowing what words immediately follow and precede a word in a sentence).***\n\nhttps://paperswithcode.com/method/bilstm#:~:text=A%20Bidirectional%20LSTM%2C%20or%20biLSTM,other%20in%20a%20backwards%20direction.","metadata":{}},{"cell_type":"code","source":"input_layer = layers.Input(shape=(1,), dtype=tf.string) # Input layer, string type(text)\nvec_layer = text_vec(input_layer) # text vectorization layer(built previous lines)\nembedding_layer_model = embedding_layer(vec_layer) # word embedding layer\nbi_lstm = layers.Bidirectional(layers.LSTM(64, activation='tanh', return_sequences=True))(embedding_layer_model) # Bidirectional-LSTM, 64 units\nlstm = layers.Bidirectional(layers.LSTM(64))(bi_lstm)\nflatten = layers.Flatten()(lstm) # Flatten layer for enering in dense layers\ndropout = layers.Dropout(.1)(flatten) # drop out layer\nx = layers.Dense(32, activation='relu')(dropout) # Dense layer\noutput_layer = layers.Dense(1, activation='sigmoid')(x) # output layer\nmodel_2 = keras.Model(input_layer, output_layer) # final model","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:12.977629Z","iopub.execute_input":"2022-02-14T07:57:12.978701Z","iopub.status.idle":"2022-02-14T07:57:13.782797Z","shell.execute_reply.started":"2022-02-14T07:57:12.978638Z","shell.execute_reply":"2022-02-14T07:57:13.782066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compile_model(model_2) # compile the model\n\nhistory_2 = fit_model(model_2, epochs=5) # fit the model","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:13.784056Z","iopub.execute_input":"2022-02-14T07:57:13.784312Z","iopub.status.idle":"2022-02-14T07:57:38.95542Z","shell.execute_reply.started":"2022-02-14T07:57:13.784279Z","shell.execute_reply":"2022-02-14T07:57:38.954587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluating the model\nmodel_2.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:38.957023Z","iopub.execute_input":"2022-02-14T07:57:38.957306Z","iopub.status.idle":"2022-02-14T07:57:40.30889Z","shell.execute_reply.started":"2022-02-14T07:57:38.957269Z","shell.execute_reply":"2022-02-14T07:57:40.308082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3 - Transfer learning with USE encoder ","metadata":{}},{"cell_type":"markdown","source":"### Transfer learning:\n> Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task. ... Common examples of transfer learning in deep learning. When to use transfer learning on your own predictive modeling problems.Dec 20, 2017\n\nsource : [machien learnign mastery](https://machinelearningmastery.com/transfer-learning-for-deep-learning/#:~:text=Transfer%20learning%20is%20a%20machine,model%20on%20a%20second%20task.&text=Common%20examples%20of%20transfer%20learning,your%20own%20predictive%20modeling%20problems.)","metadata":{}},{"cell_type":"markdown","source":"<div align=\"center\"><img src=\"https://www.analyticssteps.com/backend/media/thumbnail/1967565/9315476_1592890541_transfer.jpg\" /></div>","metadata":{}},{"cell_type":"markdown","source":"### USE layer:\n>The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. ... It comes with two variations i.e. one trained with Transformer encoder and other trained with Deep Averaging Network (DAN).\n\nsource : [towards datascience](https://towardsdatascience.com/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15#:~:text=The%20Universal%20Sentence%20Encoder%20encodes,and%20other%20natural%20language%20tasks.&text=It%20comes%20with%20two%20variations,Deep%20Averaging%20Network%20(DAN).)","metadata":{}},{"cell_type":"markdown","source":"<div align=\"center\"><img src=\"https://1.bp.blogspot.com/-1NuvtzSCb3E/XSi8XWLLBQI/AAAAAAAAETM/sl5GOt117d4KsXDy7D2-fJtp92vHiPIlACLcBGAs/s1600/image3.png\" width=800 /></div>","metadata":{}},{"cell_type":"code","source":"import tensorflow_hub as hub\n\n# model with Sequential api\nmodel_3 = keras.Sequential()\n# universal-sentence-encoder layer directly from tfhub\nuse_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n                           trainable=False,\n                           input_shape=[],\n                           dtype=tf.string,\n                           name='USE')\nmodel_3.add(use_layer)\nmodel_3.add(layers.Dropout(0.2))\nmodel_3.add(layers.Dense(64, activation=keras.activations.relu))\nmodel_3.add(layers.Dense(1, activation=keras.activations.sigmoid))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:40.310422Z","iopub.execute_input":"2022-02-14T07:57:40.310672Z","iopub.status.idle":"2022-02-14T07:57:45.899542Z","shell.execute_reply.started":"2022-02-14T07:57:40.310638Z","shell.execute_reply":"2022-02-14T07:57:45.898747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile and Fit the model using our Helper functions","metadata":{}},{"cell_type":"code","source":"compile_model(model_3)\n\nhistory_3 = fit_model(model_3, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:57:45.900667Z","iopub.execute_input":"2022-02-14T07:57:45.90278Z","iopub.status.idle":"2022-02-14T07:58:04.761965Z","shell.execute_reply.started":"2022-02-14T07:57:45.902735Z","shell.execute_reply":"2022-02-14T07:58:04.761217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing our Models resultsüìå\n### it's the time for comparing our results:\n1. we evaluate our models with our helper function.\n2. our helper function returns accuracy score, precision, recall and f1-score\n3. now we can put our results in a dataframe.\n4. now comparing our models is easy! ","metadata":{}},{"cell_type":"code","source":"baseline_model_results = evaluate_model(baseline_model, X_test_vec, y_test)\nmodel_1_results = evaluate_model(model_1, X_test, y_test)\nmodel_2_results = evaluate_model(model_2, X_test, y_test)\nmodel_3_results = evaluate_model(model_3, X_test, y_test)\n\ntotal_results = pd.DataFrame({'Random-Forest Model':baseline_model_results,\n                             'Custom-Vec-Embedding Model':model_1_results,\n                             'Bidirectional-LSTM Model':model_2_results,\n                             'USE-Transfer learning Model':model_3_results}).transpose()\n\ntotal_results","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:58:04.763704Z","iopub.execute_input":"2022-02-14T07:58:04.76397Z","iopub.status.idle":"2022-02-14T07:58:06.973074Z","shell.execute_reply.started":"2022-02-14T07:58:04.763934Z","shell.execute_reply":"2022-02-14T07:58:06.97238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plot the results","metadata":{}},{"cell_type":"code","source":"total_results.plot(figsize=(12, 8))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:58:06.974477Z","iopub.execute_input":"2022-02-14T07:58:06.974726Z","iopub.status.idle":"2022-02-14T07:58:07.223843Z","shell.execute_reply.started":"2022-02-14T07:58:06.974693Z","shell.execute_reply":"2022-02-14T07:58:07.223046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_results['accuracy'].plot(figsize=(10, 8))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:58:07.225374Z","iopub.execute_input":"2022-02-14T07:58:07.225883Z","iopub.status.idle":"2022-02-14T07:58:07.447014Z","shell.execute_reply.started":"2022-02-14T07:58:07.225838Z","shell.execute_reply":"2022-02-14T07:58:07.446235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_results['f1-score'].plot(figsize=(10, 8), color='green')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:58:07.448209Z","iopub.execute_input":"2022-02-14T07:58:07.449329Z","iopub.status.idle":"2022-02-14T07:58:07.654016Z","shell.execute_reply.started":"2022-02-14T07:58:07.449286Z","shell.execute_reply":"2022-02-14T07:58:07.653299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_results.sort_values('f1-score', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:58:07.655111Z","iopub.execute_input":"2022-02-14T07:58:07.655946Z","iopub.status.idle":"2022-02-14T07:58:07.668803Z","shell.execute_reply.started":"2022-02-14T07:58:07.655908Z","shell.execute_reply":"2022-02-14T07:58:07.668055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion ‚ö°\n#### now, it's the time to judge!! now we must doign the final step. we have our evaluation dataset and scores. so we just compare our models.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://images.squarespace-cdn.com/content/v1/5f4975941d68456fd844bb0a/1603318792575-GOER3NXNRKRZUR429XUC/Balancing+Scale+GIF\" />","metadata":{}},{"cell_type":"code","source":"total_results.sort_values('accuracy', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T07:58:07.669924Z","iopub.execute_input":"2022-02-14T07:58:07.670214Z","iopub.status.idle":"2022-02-14T07:58:07.681317Z","shell.execute_reply.started":"2022-02-14T07:58:07.670154Z","shell.execute_reply":"2022-02-14T07:58:07.680384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### metrics:\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:white;\">\n    All four models have great performances.(all of them has accuracy more than 97%)\nso it can be hard just to compare them.\n</p>\n</div>\n\n### What is the problem here?\n\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:white;\">\nwe have an imbalanced dataset, most of our data points have the label of ham, and it is natural. becuase most of sms are ham.\nin this cases, accuracy can't be a good metric. we need to see other metrics.\n</p>\n</div>\n\n### But what metric is better option?\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:white;\">\nin this probelm, false negetive and false positive are important. the metrics that give us the power of calcuating them are precision and recall, but there is one metric more, `f1-score`\n</p>\n</div>\n\n### why f1-score?\n\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:white;\">\nf1-score is the harmonic mean of precision and recall, so with one shot we can both two.\n</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div align=\"center\"><img src=\"https://lawtomated.com/wp-content/uploads/2019/10/F1-Score.png\" /></div>","metadata":{}},{"cell_type":"markdown","source":"# Final RESULT!!","metadata":{}},{"cell_type":"markdown","source":"## 1. USE(transfer learning) model\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#42f5a7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    this model gives us the best accuracy and f1-score, and also good precision and recall.\n\n</p>\n</div>\n\n## 2. Bidirectional-LSTM\n\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#42f5a7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    second model in our sorted dataframe.really close to USE model.\n</p>\n</div>\n\n## 3.Custom Text-Vectorization, Embedding + Dense layers\n\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#42f5a7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    this model has an accuracy very close to our winner, and a good f1-score, maybe if we add some layers or change hyperplanes we can win with it!\n</p>\n</div>\n\n## 4.Baseline model, Random-Forest\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#42f5a7;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    our famous machine learning model lost the competitoin, the worst recall, accuracy and f1-score made it not an excellent choice, but,\n    as a simple model without any neural net, it had a nice performance! \n</p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"# Additional Resourcesüìö\n#### 1. Major Challenges in NLP world -> https://monkeylearn.com/blog/natural-language-processing-challenges/\n#### 2. Binary classification with NLP discriminant power analysis\nhttps://medium.com/meet-nalia/binary-classification-with-nlp-discriminant-power-analysis-e02bba34b221\n#### 3. Complete Guide To Bidirectional LSTM (With Python Codes) https://analyticsindiamag.com/complete-guide-to-bidirectional-lstm-with-python-codes/#:~:text=Bidirectional%20long%2Dshort%20term%20memory,forward(past%20to%20future).\n#### 4. A Gentle Introduction to Transfer Learning in NLP https://towardsdatascience.com/a-gentle-introduction-to-transfer-learning-in-nlp-b71e87241d66\n\n#### 5. Understanding Embedding Layer in Keras\n https://medium.com/analytics-vidhya/understanding-embedding-layer-in-keras-bbe3ff1327ce","metadata":{}}]}